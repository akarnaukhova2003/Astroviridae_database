{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6aa77a14-7596-4e0d-bff5-8a7893a5c390",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "#функция для вытаскивания айдишников из файлов\n",
    "\n",
    "def get_ids(filename):\n",
    "    ids = []\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                id_part = line.split(\":\")[0]\n",
    "                ids.append(id_part)\n",
    "    return ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "79efda11-3c97-457b-9d29-4407e77e2559",
   "metadata": {},
   "outputs": [],
   "source": [
    "#по айдишникам вытаскивать описание, продукт и транслят \n",
    "from Bio import SeqIO\n",
    "from textwrap import wrap\n",
    "\n",
    "def extract_to_fasta(filename, id_list, output_fasta):\n",
    "    c=0\n",
    "    with open(output_fasta, \"w\") as out:\n",
    "        for record in SeqIO.parse(filename, \"genbank\"):\n",
    "            acc = record.name\n",
    "            if acc not in id_list:\n",
    "                continue\n",
    "            c=0\n",
    "            definition = record.description\n",
    "            for feature in record.features:\n",
    "                if feature.type == \"CDS\":\n",
    "                    c+=1\n",
    "                    product = feature.qualifiers.get(\"product\", [\"unknown_product\"])[0]\n",
    "                    translation = feature.qualifiers.get(\"translation\", [\"\"])[0]\n",
    "                    header = f\">{acc}.{c}| product: {product} | {definition}\"\n",
    "                    out.write(header + \"\\n\")\n",
    "                    seq_lines = wrap(translation, 60)\n",
    "                    out.write(\"\\n\".join(seq_lines) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "00bc1d6b-44ff-4154-bd2d-a8766bbf8cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#по айдишникам вытаскивать описание и нуклеотидную последовательность (+потом транслят по трем рамкам считывание)\n",
    "\n",
    "from Bio import SeqIO\n",
    "from textwrap import wrap\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "def extract_to_fasta_noCDS(filename, id_list, output_fasta):\n",
    "    with open(output_fasta, \"w\") as out:\n",
    "        for record in SeqIO.parse(filename, \"genbank\"):\n",
    "            acc = record.name\n",
    "            if acc not in id_list:\n",
    "                continue\n",
    "            definition = record.description\n",
    "            nucl_seq = str(record.seq)\n",
    "            for frame in range(3):\n",
    "                sub_seq = nucl_seq[frame:]                              \n",
    "                prot_seq = str(Seq(sub_seq).translate(to_stop=True))\n",
    "                if len(prot_seq) < 10:\n",
    "                    continue\n",
    "                header_prot = f\">{acc}.n+{frame} | {definition}\"\n",
    "                out.write(header_prot + \"\\n\")\n",
    "                for line in wrap(prot_seq, 50):\n",
    "                    out.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "096c7625-9f53-43a0-914e-c8dfad11f6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "conflict_annot_ids = get_ids(\"Astroviridae_15102025_conflictingannot.txt\")\n",
    "conflict_annot_ids\n",
    "filename = \"Astroviridae_15102025.gb\"\n",
    "output_fasta = \"conflict_annot_ids.fasta\"\n",
    "extract_to_fasta(filename, conflict_annot_ids, output_fasta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2da8032-7127-44eb-af3b-be05e69a3be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_annot_targetCDS_ids = get_ids(\"Astroviridae_15102025_noannot_targetCDS.txt\")\n",
    "not_annot_targetCDS_ids\n",
    "filename = \"Astroviridae_15102025.gb\"\n",
    "output_fasta = \"not_annot_targetCDS_ids.fasta\"\n",
    "extract_to_fasta(filename, not_annot_targetCDS_ids, output_fasta)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6c5053e4-776b-4b16-ad5d-fc9410c6355b",
   "metadata": {},
   "outputs": [],
   "source": [
    "not_annot_CDS_ids = get_ids(\"Astroviridae_15102025_noannotCDS.txt\")\n",
    "not_annot_CDS_ids\n",
    "filename = \"Astroviridae_15102025.gb\"\n",
    "output_fasta = \"not_annot_CDS_ids.fasta\"\n",
    "extract_to_fasta_noCDS(filename, not_annot_CDS_ids, output_fasta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "53c4336e-f820-4af4-a96f-f7ad32b2f37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      OQ709194.1|\n",
      "1      OQ709194.1|\n",
      "2      OQ709194.1|\n",
      "3      OQ709194.1|\n",
      "4      OQ709194.1|\n",
      "          ...     \n",
      "540    MW347540.1|\n",
      "541    MW347540.1|\n",
      "542    MW347540.1|\n",
      "543    MW347540.1|\n",
      "544    MW347540.1|\n",
      "Name: ID белка, Length: 545, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# для добавления название продукта в выдачу interpro\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "tsv_file = \"interpro_выдача/not_annot_targetCDS_ids_part2.tsv\"\n",
    "df = pd.read_csv(tsv_file, sep=\"\\t\")\n",
    "fasta_file = \"interpro_input/not_annot_targetCDS_ids_part2.fasta\"\n",
    "fasta_dict = {}\n",
    "print(df[\"ID белка\"])\n",
    "for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "    parts = record.description.split(\"|\", 1)\n",
    "    if len(parts) > 1:\n",
    "        fasta_id = parts[0]  # первое слово после '|'\n",
    "    else:\n",
    "        fasta_id = record.id  # fallback, если '|' нет\n",
    "    fasta_id = f\"{fasta_id}|\"\n",
    "    description = record.description\n",
    "    product = None\n",
    "    if \"product:\" in description:\n",
    "        product = description.split(\"product:\")[1].split(\"|\")[0].strip()\n",
    "    fasta_dict[fasta_id] = product\n",
    "\n",
    "df[\"product\"] = df[\"ID белка\"].map(fasta_dict)\n",
    "df = df[df[\"product\"].notna()]\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "cols.insert(1, cols.pop(cols.index(\"product\")))  # вставляем 'product' на 2-е место\n",
    "df = df[cols]\n",
    "output_file = \"not_annot_targetCDS_ids_part2_2.tsv\"\n",
    "df.to_csv(output_file, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "03da7940-4fd1-4908-b297-714bfc2f1604",
   "metadata": {},
   "outputs": [],
   "source": [
    "#удаление неподходящих источников предсказания\n",
    "import pandas as pd\n",
    "tsv_file = \"interpro_выдача/not_annot_targetCDS_ids_part2.tsv\"\n",
    "df = pd.read_csv(tsv_file, sep=\"\\t\")\n",
    "df = df[df[\"Источник предсказания\"] != \"MobiDBLite\"].copy()\n",
    "df.to_csv(\"interpro_выдача/not_annot_targetCDS_ids_part2.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b39573a9-ba72-47aa-bde8-7ace55f5cdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработан файл interpro_выдача/not_annot_targetCDS_ids_part1.tsv: Pfam+Superfamily -> interpro_выдача/not_annot_targetCDS_ids_part1_pfam_superfamily.csv, Non-Pfam+Superfamily -> interpro_выдача/not_annot_targetCDS_ids_part1_not_pfam_superfamily.csv\n",
      "Обработан файл interpro_выдача/not_annot_targetCDS_ids_part2.tsv: Pfam+Superfamily -> interpro_выдача/not_annot_targetCDS_ids_part2_pfam_superfamily.csv, Non-Pfam+Superfamily -> interpro_выдача/not_annot_targetCDS_ids_part2_not_pfam_superfamily.csv\n",
      "Обработан файл interpro_выдача/not_annot_CDS.tsv: Pfam+Superfamily -> interpro_выдача/not_annot_CDS_pfam_superfamily.csv, Non-Pfam+Superfamily -> interpro_выдача/not_annot_CDS_not_pfam_superfamily.csv\n",
      "Обработан файл interpro_выдача/conflict_annot_ids.tsv: Pfam+Superfamily -> interpro_выдача/conflict_annot_ids_pfam_superfamily.csv, Non-Pfam+Superfamily -> interpro_выдача/conflict_annot_ids_not_pfam_superfamily.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "tsv_files = [\n",
    "    \"interpro_выдача/not_annot_targetCDS_ids_part1.tsv\",\n",
    "    \"interpro_выдача/not_annot_targetCDS_ids_part2.tsv\",\n",
    "    \"interpro_выдача/not_annot_CDS.tsv\", \n",
    "    \"interpro_выдача/conflict_annot_ids.tsv\"\n",
    "]\n",
    "\n",
    "for tsv_file in tsv_files:\n",
    "    df = pd.read_csv(tsv_file, sep=\"\\t\")\n",
    "    pfam_superfamily_df = df[df['Источник предсказания'].isin(['Pfam', 'SUPERFAMILY'])]\n",
    "    not_pfam_superfamily_df = df[~df['Источник предсказания'].isin(['Pfam', 'SUPERFAMILY'])]\n",
    "    base_name = tsv_file.rsplit(\"/\", 1)[-1].replace(\".tsv\", \"\")\n",
    "    pfam_superfamily_file = f\"interpro_выдача/{base_name}_pfam_superfamily.csv\"\n",
    "    not_pfam_superfamily_file = f\"interpro_выдача/{base_name}_not_pfam_superfamily.csv\"\n",
    "    \n",
    "    pfam_superfamily_df.to_csv(pfam_superfamily_file, index=False)\n",
    "    not_pfam_superfamily_df.to_csv(not_pfam_superfamily_file, index=False)\n",
    "    \n",
    "    print(f\"Обработан файл {tsv_file}: Pfam+Superfamily -> {pfam_superfamily_file}, Non-Pfam+Superfamily -> {not_pfam_superfamily_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "f8241b96-7e17-45cb-b6a1-71683f37bc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df1 = pd.read_csv(\"interpro_выдача/not_annot_targetCDS_ids_part1.tsv\", sep=\"\\t\")\n",
    "df2 = pd.read_csv(\"interpro_выдача/not_annot_targetCDS_ids_part2.tsv\", sep=\"\\t\")\n",
    "\n",
    "merged_df = pd.concat([df1, df2], ignore_index=True)\n",
    "merged_df.to_csv(\"interpro_выдача/not_annot_targetCDS_ids.tsv\", sep=\"\\t\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "bc170b20-c924-4227-b15c-1167a11e5b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def find_ORFs(csv_files, csv_file_orf, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    orf_df = pd.read_csv(csv_file_orf, header=None).fillna('')\n",
    "    orf_list = orf_df[[0, 1]].values.tolist()\n",
    "\n",
    "    for csv_file in csv_files:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        all_results = []\n",
    "\n",
    "        for _, row in df.iterrows():\n",
    "            description = str(row.get('Описание предсказания', '')).lower()\n",
    "            matched = False\n",
    "            fixed_orfs = ['astrovirus vpg protein', 'rna helicase', \n",
    "                          'viral superfamily 1 rna helicase core domain', 'viral methyltransferase']\n",
    "            if description in [x.lower() for x in fixed_orfs]:\n",
    "                all_results.append({\n",
    "                    'ID белка': row['ID белка'],\n",
    "                    'Название семейства/белка': row.get('Название семейства/белка', ''),\n",
    "                    'Описание предсказания': row.get('Описание предсказания', ''),\n",
    "                    'Источник предсказания': row.get('Источник предсказания', ''),\n",
    "                    'Вхождение из orf': '-',\n",
    "                    'ORF': '1A',\n",
    "                    'Start': row.get('Начало', ''),\n",
    "                    'End': row.get('Конец', ''),\n",
    "                    'Source File': csv_file\n",
    "                })\n",
    "                matched = True\n",
    "            else:\n",
    "                for keyword, orf in orf_list:\n",
    "                    if keyword and keyword not in ['2', '3', 'S', 'NS']:\n",
    "                        words = keyword.lower().split()\n",
    "                        if any(word in description for word in words):\n",
    "                            all_results.append({\n",
    "                                'ID белка': row['ID белка'],\n",
    "                                'Название семейства/белка': row.get('Название семейства/белка', ''),\n",
    "                                'Описание предсказания': row.get('Описание предсказания', ''),\n",
    "                                'Источник предсказания': row.get('Источник предсказания', ''),\n",
    "                                'Вхождение из orf': keyword,\n",
    "                                'ORF': orf,\n",
    "                                'Start': row.get('Начало', ''),\n",
    "                                'End': row.get('Конец', '')\n",
    "                            })\n",
    "                            matched = True\n",
    "                            break\n",
    "\n",
    "            if not matched:\n",
    "                all_results.append({\n",
    "                    'ID белка': row['ID белка'],\n",
    "                    'Название семейства/белка': row.get('Название семейства/белка', ''),\n",
    "                    'Описание предсказания': row.get('Описание предсказания', ''),\n",
    "                    'Источник предсказания': row.get('Источник предсказания', ''),\n",
    "                    'Вхождение из orf': '-',\n",
    "                    'ORF': '-',\n",
    "                    'Start': row.get('Начало', ''),\n",
    "                    'End': row.get('Конец', '')\n",
    "                })\n",
    "\n",
    "        results_df = pd.DataFrame(all_results)\n",
    "        base_name = os.path.basename(csv_file).rsplit(\".\", 1)[0]\n",
    "        output_file = os.path.join(output_dir, f\"{base_name}_orf_results.csv\")\n",
    "        results_df.to_csv(output_file, index=False)\n",
    "        print(f\"Файл {csv_file} обработан -> {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "9da518fd-1cc2-40ff-9b69-f62ed3eda6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл interpro_выдача/not_annot_targetCDS_ids_pfam_superfamily.csv обработан -> interpro_выдача/not_annot_targetCDS_ids_pfam_superfamily_orf_results.csv\n",
      "Файл interpro_выдача/not_annot_CDS_pfam_superfamily.csv обработан -> interpro_выдача/not_annot_CDS_pfam_superfamily_orf_results.csv\n",
      "Файл interpro_выдача/conflict_annot_ids_pfam_superfamily.csv обработан -> interpro_выдача/conflict_annot_ids_pfam_superfamily_orf_results.csv\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "csv_files = [\n",
    "    \"interpro_выдача/not_annot_targetCDS_ids_pfam_superfamily.csv\",\n",
    "    \"interpro_выдача/not_annot_CDS_pfam_superfamily.csv\", \n",
    "    \"interpro_выдача/conflict_annot_ids_pfam_superfamily.csv\"\n",
    "]\n",
    "csv_file_orf = \"../ORF_names.csv\"\n",
    "output_dir = \"interpro_выдача\"\n",
    "print(find_ORFs(csv_files, csv_file_orf,output_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "d9773bbf-f841-45b3-98a6-a5a345e15e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Файл interpro_выдача/not_annot_targetCDS_ids_not_pfam_superfamily.csv обработан -> interpro_выдача/not_annot_targetCDS_ids_not_pfam_superfamily_orf_results.csv\n",
      "Файл interpro_выдача/not_annot_CDS_not_pfam_superfamily.csv обработан -> interpro_выдача/not_annot_CDS_not_pfam_superfamily_orf_results.csv\n",
      "Файл interpro_выдача/conflict_annot_ids_not_pfam_superfamily.csv обработан -> interpro_выдача/conflict_annot_ids_not_pfam_superfamily_orf_results.csv\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "csv_files = [\n",
    "    \"interpro_выдача/not_annot_targetCDS_ids_not_pfam_superfamily.csv\",\n",
    "    \"interpro_выдача/not_annot_CDS_not_pfam_superfamily.csv\", \n",
    "    \"interpro_выдача/conflict_annot_ids_not_pfam_superfamily.csv\"\n",
    "]\n",
    "csv_file_orf = \"../ORF_names.csv\"\n",
    "output_dir = \"interpro_выдача\"\n",
    "print(find_ORFs(csv_files, csv_file_orf,output_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "41e428ce-d535-42f2-9f4a-d887cd3113d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#функуия для поиска айдишников, для которых interpro ничего не нашел\n",
    "\n",
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "\n",
    "def filter_fasta_by_csv(fasta_file, csv_file, output_txt):\n",
    "    df = pd.read_csv(csv_file, sep='\\t')\n",
    "    ids_to_skip = set(str(x).split('|')[0].strip() for x in df['ID белка'])\n",
    "    \n",
    "    count_written = 0\n",
    "    with open(output_txt, \"w\") as out_f:\n",
    "        for record in SeqIO.parse(fasta_file, \"fasta\"):\n",
    "            record_id = str(record.id).split(\"|\")[0].strip()\n",
    "            if record_id not in ids_to_skip:\n",
    "                out_f.write(record.description + \"\\n\")\n",
    "                count_written += 1\n",
    "\n",
    "    print(f\"Готово! Записано {count_written} записей в {output_txt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "79a7da67-3ead-4a10-8412-a15f469b0e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Готово! Записано 3 записей в not_find_interpro/conflict_annot_ids_not_find.txt\n",
      "Готово! Записано 13 записей в not_find_interpro/not_annot_targetCDS_ids_not_find.txt\n",
      "Готово! Записано 42 записей в not_find_interpro/not_annot_CDS_ids_not_find.txt\n"
     ]
    }
   ],
   "source": [
    "all = [['interpro_input/conflict_annot_ids.fasta', 'interpro_выдача/conflict_annot_ids.tsv', 'not_find_interpro/conflict_annot_ids_not_find.txt'], \n",
    "       ['interpro_input/not_annot_targetCDS_ids.fasta', 'interpro_выдача/not_annot_targetCDS_ids.tsv', 'not_find_interpro/not_annot_targetCDS_ids_not_find.txt'],\n",
    "       ['interpro_input/not_annot_CDS_ids.fasta', 'interpro_выдача/not_annot_CDS.tsv', 'not_find_interpro/not_annot_CDS_ids_not_find.txt']\n",
    "]\n",
    "\n",
    "for el in all:\n",
    "    filter_fasta_by_csv(el[0], el[1], el[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11d8372-edba-4cb7-aad0-1dc6b9d9283a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
